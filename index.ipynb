{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neocov.read_data import *\n",
    "from neocov.preproc import *\n",
    "from neocov.type_emb import *\n",
    "from neocov.communities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/'\n",
    "COMMENTS_DIAC_DIR = f'{DATA_DIR}comments/by_date/'\n",
    "OUT_DIR = '../out/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeoCov\n",
    "\n",
    "> Semantic change and social semantic variation of Covid-related English neologisms on Reddit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = '2020'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_paths_year = get_comments_paths_year(COMMENTS_DIAC_DIR, YEAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "comments = read_comm_csvs(comment_paths_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "comments_clean = clean_comments(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = comments_clean['body'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{OUT_DIR}docs_clean/diac_{YEAR}.pickle', 'wb') as fp:\n",
    "    pickle.dump(docs, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{OUT_DIR}docs_clean/diac_{YEAR}.pickle', 'rb') as fp:\n",
    "    docs = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-driving",
   "metadata": {},
   "source": [
    "#### Create corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = train_model(corpus, EPOCHS=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-flash",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'{OUT_DIR}models/{YEAR}_ep-20.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-necessity",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2019 = Word2Vec.load(f'{OUT_DIR}models/2019_ep-20.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2020 = Word2Vec.load(f'{OUT_DIR}models/2020_ep-20.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-blank",
   "metadata": {},
   "source": [
    "### Align models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2019_vocab = len(model_2019.wv.key_to_index)\n",
    "model_2020_vocab = len(model_2020.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_procrustes_align_gensim(model_2019, model_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(model_2019.wv.key_to_index) == len(model_2020.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_vocab = pd.DataFrame(\n",
    "    columns=['Model', 'Words'],\n",
    "    data=[\n",
    "        ['2019', model_2019_vocab],\n",
    "        ['2020', model_2020_vocab],\n",
    "        ['intersection', len(model_2019.wv.key_to_index)]\n",
    "    ],\n",
    ")\n",
    "\n",
    "models_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_vocab.to_csv(f'{OUT_DIR}models_vocab.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-lighting",
   "metadata": {},
   "source": [
    "### Measure distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = measure_distances(model_2019, model_2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: filter by true type frequency; `Gensim`'s type frequency seems incorrect; it probably reflects frequency ranks instead of total counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist_lex = load_blacklist_lex()\n",
    "\n",
    "k = 500\n",
    "freq_min = 100\n",
    "\n",
    "sem_change_cands = (distances\\\n",
    "    .query('freq_1 > @freq_min and freq_2 > @freq_min')\n",
    "    .query('lex.str.isalpha() == True')\n",
    "    .query('lex.str.len() > 3')\n",
    "    .query('lex not in @blacklist_lex')\n",
    "    .nlargest(k, 'dist_sem')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "sem_change_cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_change_cands_out = (sem_change_cands\n",
    "    .nlargest(100, 'dist_sem')\n",
    "    .assign(index_1 = lambda df: df.index + 1)\n",
    "    .assign(dist_sem = lambda df: df['dist_sem'].round(2))\n",
    "    .assign(dist_sem = lambda df: df['dist_sem'].apply('{:.2f}'.format))\n",
    "    .rename({'index_1': '', 'lex': 'Lexeme', 'dist_sem': 'SemDist'}, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_change_cands_out.to_csv(\n",
    "        f'{OUT_DIR}sem_change_cands.csv',\n",
    "        columns=['', 'Lexeme', 'SemDist'],\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-tomato",
   "metadata": {},
   "source": [
    "### Inspect nearest neighbours of lexemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEX_NBS = 'ahahahah'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs_model_1, nbs_model_2 = get_nearest_neighbours_models(\n",
    "    lex=LEX_NBS, \n",
    "    freq_min=1,\n",
    "    model_1=model_2019, \n",
    "    model_2=model_2020,\n",
    "    k=10\n",
    ")\n",
    "\n",
    "display(\n",
    "    nbs_model_1,\n",
    "    nbs_model_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not related to Covid:\n",
    "\n",
    "- sunsetting: > gaming-related meaning in 2020\n",
    "- childe: > gaming-related proper name in 2020\n",
    "- megalodon: > gaming-related proper name in 2020\n",
    "- newf: (derogatory) slang term for people from Newfoundland (Canada)\n",
    "- chaz: > Capitol Hill Autonomous Zone (CHAZ)\n",
    "- klee: > computer game character, proper name\n",
    "- rittenhouse: whiskey brand > proper name, involved in shooting related to BLM protests\n",
    "\n",
    "Related to Covid:\n",
    "\n",
    "- cerb: > Canada Emergency Response Benefit for Covid\n",
    "- vacuo: > medical term, 'vacuum'\n",
    "- moderna: > vaccine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social semantic variation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-chorus",
   "metadata": {},
   "source": [
    "### Inspect subreddits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-coordinator",
   "metadata": {},
   "source": [
    "#### read comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_dir_path = Path('../data/comments/lexeme/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_paths = list(comments_dir_path.glob(f'Covid*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "comments = read_comm_csvs(comments_paths)\n",
    "comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: filter comments\n",
    "\n",
    "- [ ] remove duplicates\n",
    "- [ ] remove bots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-rocket",
   "metadata": {},
   "source": [
    "#### get subreddit counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "subr_counts = get_subr_counts(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "subr_counts_plt = plot_subr_counts(subr_counts, k=20)\n",
    "subr_counts_plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "subr_counts_plt.save(f'{OUT_DIR}subr_counts.png', scale_factor=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-kentucky",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMENTS_DIR_SUBR = '../data/comments/subr/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBR = 'conspiracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpaths = get_comments_paths_subr(COMMENTS_DIR_SUBR, SUBR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "comments = read_comm_csvs(fpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "comments_clean = clean_comments(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = comments_clean['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = docs.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{OUT_DIR}docs_clean/subr_{SUBR}.pickle', 'wb') as fp:\n",
    "    pickle.dump(docs, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{OUT_DIR}docs_clean/subr_{SUBR}.pickle', 'rb') as fp:\n",
    "    docs = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus information\n",
    "\n",
    "| Subreddit          | Comments  | DateFirst  | DateLast   |\n",
    "|:-------------------|---------: |:-----------|:-----------|\n",
    "| LockdownSkepticism |   520,392 | 2020-03-26 | 2020-12-27 |  \n",
    "| Coronavirus        | 4,121,144 | 2020-01-21 | 2020-12-27 |\n",
    "| conspiracy         | 3,973,514 | 2020-01-01 | 2020-12-27 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = train_model(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'{OUT_DIR}models/{SUBR}.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-necessity",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBRS = ['Coronavirus', 'LockdownSkepticism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Word2Vec.load(f'{OUT_DIR}models/{SUBRS[0]}.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Word2Vec.load(f'{OUT_DIR}models/{SUBRS[1]}.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-blank",
   "metadata": {},
   "source": [
    "### Align models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_vocab = len(model_1.wv.key_to_index)\n",
    "model_2_vocab = len(model_2.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-clerk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37317 37317\n",
      "37317 37317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x187dbcfa0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smart_procrustes_align_gensim(model_1, model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(model_1.wv.key_to_index) == len(model_2.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-cutting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>94816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LockdownSkepticism</td>\n",
       "      <td>38926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>intersection</td>\n",
       "      <td>37317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Words\n",
       "0         Coronavirus  94816\n",
       "1  LockdownSkepticism  38926\n",
       "2        intersection  37317"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_vocab = pd.DataFrame(\n",
    "    columns=['Model', 'Words'],\n",
    "    data=[\n",
    "        [SUBRS[0], model_1_vocab],\n",
    "        [SUBRS[1], model_2_vocab],\n",
    "        ['intersection', len(model_1.wv.key_to_index)]\n",
    "    ],\n",
    ")\n",
    "\n",
    "models_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_vocab.to_csv(f'{OUT_DIR}models_subrs_vocab.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-lighting",
   "metadata": {},
   "source": [
    "### Measure distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = measure_distances(model_1, model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### words that differ the most between both communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-cannon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lex</th>\n",
       "      <th>dist_sem</th>\n",
       "      <th>freq_1</th>\n",
       "      <th>freq_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plandemic</td>\n",
       "      <td>0.892523</td>\n",
       "      <td>789</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scams</td>\n",
       "      <td>0.889811</td>\n",
       "      <td>964</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vigorous</td>\n",
       "      <td>0.866856</td>\n",
       "      <td>647</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>likewise</td>\n",
       "      <td>0.843846</td>\n",
       "      <td>1444</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>borderline</td>\n",
       "      <td>0.829629</td>\n",
       "      <td>34936</td>\n",
       "      <td>6561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>examining</td>\n",
       "      <td>0.827804</td>\n",
       "      <td>1337</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>review</td>\n",
       "      <td>0.824861</td>\n",
       "      <td>20052</td>\n",
       "      <td>3647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>improved</td>\n",
       "      <td>0.822236</td>\n",
       "      <td>17517</td>\n",
       "      <td>3032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>examination</td>\n",
       "      <td>0.813457</td>\n",
       "      <td>1314</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>blurred</td>\n",
       "      <td>0.807373</td>\n",
       "      <td>634</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>approved</td>\n",
       "      <td>0.805417</td>\n",
       "      <td>39951</td>\n",
       "      <td>7422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>soliciting</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>3903</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cargo</td>\n",
       "      <td>0.803016</td>\n",
       "      <td>616</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>choke</td>\n",
       "      <td>0.800872</td>\n",
       "      <td>1171</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>internally</td>\n",
       "      <td>0.799448</td>\n",
       "      <td>574</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>coverage</td>\n",
       "      <td>0.794310</td>\n",
       "      <td>10972</td>\n",
       "      <td>1934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>screened</td>\n",
       "      <td>0.791834</td>\n",
       "      <td>15463</td>\n",
       "      <td>2759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mega</td>\n",
       "      <td>0.791515</td>\n",
       "      <td>2167</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>speculate</td>\n",
       "      <td>0.789921</td>\n",
       "      <td>13655</td>\n",
       "      <td>2379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>reliable</td>\n",
       "      <td>0.787391</td>\n",
       "      <td>69524</td>\n",
       "      <td>13660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lex  dist_sem  freq_1  freq_2\n",
       "0     plandemic  0.892523     789     138\n",
       "1         scams  0.889811     964     167\n",
       "2      vigorous  0.866856     647     114\n",
       "3      likewise  0.843846    1444     251\n",
       "4    borderline  0.829629   34936    6561\n",
       "5     examining  0.827804    1337     234\n",
       "6        review  0.824861   20052    3647\n",
       "7      improved  0.822236   17517    3032\n",
       "8   examination  0.813457    1314     229\n",
       "9       blurred  0.807373     634     112\n",
       "10     approved  0.805417   39951    7422\n",
       "11   soliciting  0.805046    3903     692\n",
       "12        cargo  0.803016     616     108\n",
       "13        choke  0.800872    1171     205\n",
       "14   internally  0.799448     574     101\n",
       "15     coverage  0.794310   10972    1934\n",
       "16     screened  0.791834   15463    2759\n",
       "17         mega  0.791515    2167     389\n",
       "18    speculate  0.789921   13655    2379\n",
       "19     reliable  0.787391   69524   13660"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blacklist_lex = load_blacklist_lex()\n",
    "\n",
    "k = 20\n",
    "freq_min = 100\n",
    "\n",
    "sem_change_cands = (distances\\\n",
    "    .query('freq_1 > @freq_min and freq_2 > @freq_min')\n",
    "    .query('lex.str.isalpha() == True')\n",
    "    .query('lex.str.len() > 3')\n",
    "    .query('lex not in @blacklist_lex')\n",
    "    .nlargest(k, 'dist_sem')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "sem_change_cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_change_cands_out = (sem_change_cands\n",
    "    .nlargest(100, 'dist_sem')\n",
    "    .assign(index_1 = lambda df: df.index + 1)\n",
    "    .assign(dist_sem = lambda df: df['dist_sem'].round(2))\n",
    "    .assign(dist_sem = lambda df: df['dist_sem'].apply('{:.2f}'.format))\n",
    "    .rename({'index_1': '', 'lex': 'Lexeme', 'dist_sem': 'SemDist'}, axis=1)\n",
    ")\n",
    "sem_change_cands_out.to_csv(\n",
    "        f'{OUT_DIR}sem_var_soc_cands.csv',\n",
    "        columns=['', 'Lexeme', 'SemDist'],\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nearest neighbours for target lexemes in both communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEX_NBS = 'lockdown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-majority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>lex</th>\n",
       "      <th>similarity</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>shutdown</td>\n",
       "      <td>0.844873</td>\n",
       "      <td>8598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>lockdowns</td>\n",
       "      <td>0.768522</td>\n",
       "      <td>50035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>shutdowns</td>\n",
       "      <td>0.661069</td>\n",
       "      <td>3037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>curfew</td>\n",
       "      <td>0.613175</td>\n",
       "      <td>1652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>quarantine</td>\n",
       "      <td>0.600933</td>\n",
       "      <td>40419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>restrictions</td>\n",
       "      <td>0.581443</td>\n",
       "      <td>31971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>quarantines</td>\n",
       "      <td>0.568791</td>\n",
       "      <td>2767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>quarentine</td>\n",
       "      <td>0.540457</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>curfews</td>\n",
       "      <td>0.536410</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>containment</td>\n",
       "      <td>0.515410</td>\n",
       "      <td>4363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model           lex  similarity   freq\n",
       "0      1      shutdown    0.844873   8598\n",
       "1      1     lockdowns    0.768522  50035\n",
       "2      1     shutdowns    0.661069   3037\n",
       "3      1        curfew    0.613175   1652\n",
       "4      1    quarantine    0.600933  40419\n",
       "5      1  restrictions    0.581443  31971\n",
       "6      1   quarantines    0.568791   2767\n",
       "7      1    quarentine    0.540457    454\n",
       "8      1       curfews    0.536410    751\n",
       "9      1   containment    0.515410   4363"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>lex</th>\n",
       "      <th>similarity</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29861</th>\n",
       "      <td>2</td>\n",
       "      <td>lockdowns</td>\n",
       "      <td>0.737042</td>\n",
       "      <td>9460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29862</th>\n",
       "      <td>2</td>\n",
       "      <td>shutdown</td>\n",
       "      <td>0.727802</td>\n",
       "      <td>1489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29863</th>\n",
       "      <td>2</td>\n",
       "      <td>lockdowners</td>\n",
       "      <td>0.599373</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29864</th>\n",
       "      <td>2</td>\n",
       "      <td>shutdowns</td>\n",
       "      <td>0.584469</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29865</th>\n",
       "      <td>2</td>\n",
       "      <td>maskers</td>\n",
       "      <td>0.572266</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29866</th>\n",
       "      <td>2</td>\n",
       "      <td>vaxxers</td>\n",
       "      <td>0.557066</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29867</th>\n",
       "      <td>2</td>\n",
       "      <td>masker</td>\n",
       "      <td>0.541411</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29868</th>\n",
       "      <td>2</td>\n",
       "      <td>vax</td>\n",
       "      <td>0.522942</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29869</th>\n",
       "      <td>2</td>\n",
       "      <td>vaxx</td>\n",
       "      <td>0.508261</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29870</th>\n",
       "      <td>2</td>\n",
       "      <td>lock</td>\n",
       "      <td>0.490704</td>\n",
       "      <td>9527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model          lex  similarity  freq\n",
       "29861      2    lockdowns    0.737042  9460\n",
       "29862      2     shutdown    0.727802  1489\n",
       "29863      2  lockdowners    0.599373   156\n",
       "29864      2    shutdowns    0.584469   545\n",
       "29865      2      maskers    0.572266   660\n",
       "29866      2      vaxxers    0.557066   465\n",
       "29867      2       masker    0.541411   177\n",
       "29868      2          vax    0.522942   504\n",
       "29869      2         vaxx    0.508261   132\n",
       "29870      2         lock    0.490704  9527"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nbs_model_1, nbs_model_2 = get_nearest_neighbours_models(\n",
    "    lex=LEX_NBS, \n",
    "    freq_min=50,\n",
    "    model_1=model_1, \n",
    "    model_2=model_2,\n",
    "    k=10\n",
    ")\n",
    "\n",
    "display(\n",
    "    nbs_model_1,\n",
    "    nbs_model_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### embeddings projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append({'subreddit': SUBRS[0], 'model': model_1})\n",
    "models.append({'subreddit': SUBRS[1], 'model': model_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sem_axis(model, pole_word_1: str, pole_word_2: str):\n",
    "\tpole_1_vec = model_1.wv.get_vector(pole_1)\n",
    "\tpole_2_vec = model_1.wv.get_vector(pole_2)\n",
    "\tsem_axis = pole_1_vec - pole_2_vec\n",
    "\treturn sem_axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_axis_sim(lex: str, pole_word_1: str, pole_word_2: str, model):\n",
    "\tsem_axis = make_sem_axis(model, pole_word_1, pole_word_2)\n",
    "\tlex_vec = model.wv.get_vector(lex)\n",
    "\tsim_cos = 1 - spatial.distance.cosine(lex_vec, sem_axis)\n",
    "\treturn sim_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = 'lockdown'\n",
    "pole_1 = 'good'\n",
    "pole_2 = 'bad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coronavirus: -0.08022712916135788\n",
      "LockdownSkepticism: -0.12990982830524445\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "\tprint(f'{model[\"subreddit\"]}: {get_axis_sim(lex, pole_1, pole_2, model[\"model\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexs = [\n",
    "\t'lockdown', 'lockdowns', \n",
    "\t'shutdown', 'shutdowns', \n",
    "\t'vaccine', 'vaccines', \n",
    "\t'mask', 'masks',\n",
    "\t'order', 'police',\n",
    "\t'thing', 'tree', 'yellow', 'give'\n",
    "\t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = []\n",
    "for lex in lexs:\n",
    "\tfor model in models:\n",
    "\t\tsim = {}\n",
    "\t\tsim['subreddit'] = model['subreddit']\n",
    "\t\tsim['lex'] = lex\n",
    "\t\tsim['sim'] = get_axis_sim(lex, pole_1, pole_2, model['model'])\n",
    "\t\tsims.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-f24e3dd75fe24eb18ab424c719bb51b9\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-f24e3dd75fe24eb18ab424c719bb51b9\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-f24e3dd75fe24eb18ab424c719bb51b9\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-c9778c8940eb52a5fea98a46ae8ba2b0\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"subreddit\", \"type\": \"nominal\"}, \"x\": {\"field\": \"sim\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"lex\", \"sort\": null, \"type\": \"nominal\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-c9778c8940eb52a5fea98a46ae8ba2b0\": [{\"subreddit\": \"Coronavirus\", \"lex\": \"lockdown\", \"sim\": -0.08022712916135788}, {\"subreddit\": \"LockdownSkepticism\", \"lex\": \"lockdown\", \"sim\": -0.12990982830524445}, {\"subreddit\": \"Coronavirus\", \"lex\": \"lockdowns\", \"sim\": -0.06833521276712418}, {\"subreddit\": \"LockdownSkepticism\", \"lex\": \"lockdowns\", \"sim\": -0.0952957272529602}, {\"subreddit\": \"Coronavirus\", \"lex\": \"shutdown\", \"sim\": -0.11067618429660797}, {\"subreddit\": \"LockdownSkepticism\", \"lex\": \"shutdown\", \"sim\": -0.14383257925510406}, {\"subreddit\": \"Coronavirus\", \"lex\": \"shutdowns\", \"sim\": -0.07748658210039139}, {\"subreddit\": \"LockdownSkepticism\", \"lex\": \"shutdowns\", \"sim\": -0.09972812980413437}, {\"subreddit\": \"Coronavirus\", \"lex\": \"vaccine\", \"sim\": -0.008722450584173203}, {\"subreddit\": \"LockdownSkepticism\", \"lex\": \"vaccine\", \"sim\": -0.008453463204205036}, {\"subreddit\": \"Coronavirus\", \"lex\": \"vaccines\", \"sim\": 0.030203502625226974}, {\"subreddit\": \"LockdownSkepticism\", \"lex\": \"vaccines\", \"sim\": 0.021412456408143044}, {\"subreddit\": \"Coronavirus\", \"lex\": \"mask\", \"sim\": 0.05741423740983009}, {\"subreddit\": \"LockdownSkepticism\", \"lex\": \"mask\", \"sim\": 0.03356524184346199}, {\"subreddit\": \"Coronavirus\", \"lex\": \"masks\", \"sim\": 0.04498105123639107}, {\"subreddit\": \"LockdownSkepticism\", \"lex\": \"masks\", \"sim\": 0.025375308468937874}, {\"subreddit\": \"Coronavirus\", \"lex\": \"order\", \"sim\": 0.0858086347579956}, {\"subreddit\": \"LockdownSkepticism\", \"lex\": \"order\", \"sim\": 0.0058347503654658794}, {\"subreddit\": \"Coronavirus\", \"lex\": \"police\", \"sim\": 0.03616446256637573}, {\"subreddit\": \"LockdownSkepticism\", \"lex\": \"police\", \"sim\": -0.022389892488718033}, {\"subreddit\": \"Coronavirus\", \"lex\": \"thing\", \"sim\": -0.08811882138252258}, {\"subreddit\": \"LockdownSkepticism\", \"lex\": \"thing\", \"sim\": -0.10003308206796646}, {\"subreddit\": \"Coronavirus\", \"lex\": \"tree\", \"sim\": -0.01825425587594509}, {\"subreddit\": \"LockdownSkepticism\", \"lex\": \"tree\", \"sim\": -0.01272513810545206}, {\"subreddit\": \"Coronavirus\", \"lex\": \"yellow\", \"sim\": -0.13428929448127747}, {\"subreddit\": \"LockdownSkepticism\", \"lex\": \"yellow\", \"sim\": -0.15483997762203217}, {\"subreddit\": \"Coronavirus\", \"lex\": \"give\", \"sim\": 0.11482276022434235}, {\"subreddit\": \"LockdownSkepticism\", \"lex\": \"give\", \"sim\": 0.0988151878118515}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims_df = pd.DataFrame(sims)\n",
    "\n",
    "alt.Chart(sims_df).mark_line(point=True).encode(\n",
    "\tx='sim',\n",
    "\ty=alt.Y('lex', sort=None),\n",
    "\tcolor='subreddit'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### biggest discrepancies in nearest neighbours for target lexemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs_model_1, nbs_model_2 = get_nearest_neighbours_models(\n",
    "    lex=LEX, \n",
    "    freq_min=150,\n",
    "    model_1=model_1, \n",
    "    model_2=model_2,\n",
    "    k=100_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs_diffs = pd.merge(\n",
    "    nbs_model_1, nbs_model_2, \n",
    "    on='lex',\n",
    "    suffixes = ('_1', '_2')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-audience",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs_diffs = nbs_diffs\\\n",
    "    .assign(sim_diff = abs(nbs_diffs['similarity_1'] - nbs_diffs['similarity_2']))\\\n",
    "    .sort_values('sim_diff', ascending=False)\\\n",
    "    .reset_index(drop=True)\\\n",
    "    .query('lex.str.len() >= 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "topn = 10\n",
    "\n",
    "subr_1_nbs = nbs_diffs\\\n",
    "    .query('similarity_1 > similarity_2')\\\n",
    "    .nlargest(topn, 'sim_diff')\n",
    "\n",
    "subr_2_nbs = nbs_diffs\\\n",
    "    .query('similarity_2 > similarity_1')\\\n",
    "    .nlargest(topn, 'sim_diff')\n",
    "\n",
    "display(subr_1_nbs, subr_2_nbs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
