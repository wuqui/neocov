# AUTOGENERATED! DO NOT EDIT! File to edit: 01_preproc.ipynb (unless otherwise specified).

__all__ = ['log_step', 'conv_to_lowerc', 'rm_punct', 'tokenize', 'count_toks', 'rem_short_comments', 'clean_comments',
           'load_blacklist_lex']

# Cell
from functools import wraps
import datetime as dt
import re
import pandas as pd
import pandas.testing as pdt

# Cell
def log_step(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        tic = dt.datetime.now()
        result = func(*args, **kwargs)
        time_taken = str(dt.datetime.now() - tic)
        print(f"{func.__name__:20} {str(result.shape):10} {time_taken:20}")
        return result
    return wrapper

# Cell
@log_step
def conv_to_lowerc(comments):
	return comments\
            .assign(body=lambda x: x['body'].str.lower())

# Cell
@log_step
def rm_punct(comments):
    return comments\
        .assign(body=lambda x: x['body'].str.replace(r'[^\w\s]+', ' ', regex=True))


# Cell
@log_step
def tokenize(comments):
	return comments\
	.assign(body = lambda x: x['body'].str.split())

# Cell
def count_toks(comments):
	return comments\
            .assign(toks=lambda x: x['body'].map(len))


# Cell
@log_step
def rem_short_comments(comments, min_toks=10):
	return comments\
            .pipe(count_toks)\
            .query('toks > @min_toks')\
            .drop('toks', axis=1)
	

# Cell
def clean_comments(comments):
	return comments\
            .pipe(conv_to_lowerc)\
            .pipe(rm_punct)\
            .pipe(tokenize)\
            .pipe(rem_short_comments)


# Cell
def load_blacklist_lex(fpath='../data/blacklist_lex.csv'):
    return (pd.read_csv(fpath)
        .query('Excl == True')
        .loc[:, 'Lex']
    )