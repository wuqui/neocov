{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neocov.read_data import *\n",
    "from neocov.preproc import *\n",
    "from neocov.type_emb import *\n",
    "from neocov.communities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "import altair as alt\n",
    "from altair_saver import save\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/'\n",
    "COMMENTS_DIAC_DIR = f'{DATA_DIR}comments/by_date/'\n",
    "OUT_DIR = '../out/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeoCov\n",
    "\n",
    "> Semantic change and social semantic variation of Covid-related English neologisms on Reddit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = '2020'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_paths_year = get_comments_paths_year(COMMENTS_DIAC_DIR, YEAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "comments = read_comm_csvs(comment_paths_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "comments_clean = clean_comments(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = comments_clean['body'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{OUT_DIR}docs_clean/diac_{YEAR}.pickle', 'wb') as fp:\n",
    "    pickle.dump(docs, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{OUT_DIR}docs_clean/diac_{YEAR}.pickle', 'rb') as fp:\n",
    "    docs = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-driving",
   "metadata": {},
   "source": [
    "#### Create corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = train_model(corpus, EPOCHS=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-flash",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'{OUT_DIR}models/{YEAR}_ep-20.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-necessity",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2019 = Word2Vec.load(f'{OUT_DIR}models/2019_ep-20.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2020 = Word2Vec.load(f'{OUT_DIR}models/2020_ep-20.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-blank",
   "metadata": {},
   "source": [
    "### Align models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2019_vocab = len(model_2019.wv.key_to_index)\n",
    "model_2020_vocab = len(model_2020.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_procrustes_align_gensim(model_2019, model_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(model_2019.wv.key_to_index) == len(model_2020.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_vocab = pd.DataFrame(\n",
    "    columns=['Model', 'Words'],\n",
    "    data=[\n",
    "        ['2019', model_2019_vocab],\n",
    "        ['2020', model_2020_vocab],\n",
    "        ['intersection', len(model_2019.wv.key_to_index)]\n",
    "    ],\n",
    ")\n",
    "\n",
    "models_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_vocab.to_csv(f'{OUT_DIR}models_vocab.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-lighting",
   "metadata": {},
   "source": [
    "### Measure distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = measure_distances(model_2019, model_2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: filter by true type frequency; `Gensim`'s type frequency seems incorrect; it probably reflects frequency ranks instead of total counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist_lex = load_blacklist_lex()\n",
    "\n",
    "k = 20\n",
    "freq_min = 100\n",
    "\n",
    "sem_change_cands = (distances\\\n",
    "    .query('freq_1 > @freq_min and freq_2 > @freq_min')\n",
    "    .query('lex.str.isalpha() == True')\n",
    "    .query('lex.str.len() > 3')\n",
    "    .query('lex not in @blacklist_lex')\n",
    "    .nlargest(k, 'dist_sem')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "sem_change_cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_change_cands_out = (sem_change_cands\n",
    "    .nlargest(100, 'dist_sem')\n",
    "    .assign(index_1 = lambda df: df.index + 1)\n",
    "    .assign(dist_sem = lambda df: df['dist_sem'].round(2))\n",
    "    .assign(dist_sem = lambda df: df['dist_sem'].apply('{:.2f}'.format))\n",
    "    .rename({'index_1': '', 'lex': 'Lexeme', 'dist_sem': 'SemDist'}, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_change_cands_out.to_csv(\n",
    "        f'{OUT_DIR}sem_change_cands.csv',\n",
    "        columns=['', 'Lexeme', 'SemDist'],\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-tomato",
   "metadata": {},
   "source": [
    "### Inspect nearest neighbours of lexemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEX_NBS = 'lockdowns'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs_model_1, nbs_model_2 = get_nearest_neighbours_models(\n",
    "    lex=LEX_NBS, \n",
    "    freq_min=1,\n",
    "    model_1=model_2019, \n",
    "    model_2=model_2020,\n",
    "    k=10\n",
    ")\n",
    "\n",
    "display(\n",
    "    nbs_model_1,\n",
    "    nbs_model_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not related to Covid:\n",
    "\n",
    "- sunsetting: > gaming-related meaning in 2020\n",
    "- childe: > gaming-related proper name in 2020\n",
    "- megalodon: > gaming-related proper name in 2020\n",
    "- newf: (derogatory) slang term for people from Newfoundland (Canada)\n",
    "- chaz: > Capitol Hill Autonomous Zone (CHAZ)\n",
    "- klee: > computer game character, proper name\n",
    "- rittenhouse: whiskey brand > proper name, involved in shooting related to BLM protests\n",
    "\n",
    "Related to Covid:\n",
    "\n",
    "- cerb: > Canada Emergency Response Benefit for Covid\n",
    "- vacuo: > medical term, 'vacuum'\n",
    "- moderna: > vaccine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social semantic variation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-chorus",
   "metadata": {},
   "source": [
    "### Inspect subreddits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-coordinator",
   "metadata": {},
   "source": [
    "#### read comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_dir_path = Path('../data/comments/lexeme/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_paths = list(comments_dir_path.glob(f'Covid*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "comments = read_comm_csvs(comments_paths)\n",
    "comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-rocket",
   "metadata": {},
   "source": [
    "#### get subreddit counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "subr_counts = get_subr_counts(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "subr_counts_plt = plot_subr_counts(subr_counts, k=15)\n",
    "subr_counts_plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "subr_counts_plt.save(f'{OUT_DIR}subr_counts.png', scale_factor=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-kentucky",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMENTS_DIR_SUBR = '../data/comments/subr/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBR = 'conspiracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpaths = get_comments_paths_subr(COMMENTS_DIR_SUBR, SUBR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "comments = read_comm_csvs(fpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "comments_clean = clean_comments(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = comments_clean['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = docs.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{OUT_DIR}docs_clean/subr_{SUBR}.pickle', 'wb') as fp:\n",
    "    pickle.dump(docs, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{OUT_DIR}docs_clean/subr_{SUBR}.pickle', 'rb') as fp:\n",
    "    docs = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus information\n",
    "\n",
    "| Subreddit          | Comments  | DateFirst  | DateLast   |\n",
    "|:-------------------|---------: |:-----------|:-----------|\n",
    "| LockdownSkepticism |   520,392 | 2020-03-26 | 2020-12-27 |  \n",
    "| Coronavirus        | 4,121,144 | 2020-01-21 | 2020-12-27 |\n",
    "| conspiracy         | 3,973,514 | 2020-01-01 | 2020-12-27 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = train_model(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'{OUT_DIR}models/{SUBR}.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-necessity",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['Coronavirus', 'conspiracy']\n",
    "# model_names = ['Coronavirus', 'LockdownSkepticism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Coronavirus',\n",
       "  'path': '../out/models/Coronavirus.model',\n",
       "  'model': <gensim.models.word2vec.Word2Vec at 0x16624e800>},\n",
       " {'name': 'conspiracy',\n",
       "  'path': '../out/models/conspiracy.model',\n",
       "  'model': <gensim.models.word2vec.Word2Vec at 0x17359ffd0>}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [dict() for name in model_names]\n",
    "for i, model in enumerate(models):\n",
    "\tmodel['name'] = model_names[i]\n",
    "\tmodel['path'] = f'../out/models/{model[\"name\"]}.model'\n",
    "\tmodel['model'] = Word2Vec.load(model['path'])\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-blank",
   "metadata": {},
   "source": [
    "### Align models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "\tmodel['vocab'] = len(model['model'].wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-clerk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67181 67181\n",
      "67181 67181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x17359ffd0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smart_procrustes_align_gensim(models[0]['model'], models[1]['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(models[0]['model'].wv.key_to_index) == len(models[1]['model'].wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_vocab = (pd.DataFrame(models)\n",
    "\t.filter(['name', 'vocab'])\n",
    "\t.rename({'name': 'Model', 'vocab': 'Words'}, axis=1)\n",
    ")\n",
    "\n",
    "models_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_vocab.to_csv(f'../out/vocabs/vocab_{models[0][\"name\"]}--{models[1][\"name\"]}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-lighting",
   "metadata": {},
   "source": [
    "### Measure distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = measure_distances(models[0]['model'], models[1]['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### words that differ the most between both communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist_lex = load_blacklist_lex()\n",
    "\n",
    "k = 20\n",
    "freq_min = 100\n",
    "\n",
    "sem_change_cands = (distances\\\n",
    "    .query('freq_1 > @freq_min and freq_2 > @freq_min')\n",
    "    .query('lex.str.isalpha() == True')\n",
    "    .query('lex.str.len() > 3')\n",
    "    .query('lex not in @blacklist_lex')\n",
    "    .nlargest(k, 'dist_sem')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "sem_change_cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_change_cands_out = (sem_change_cands\n",
    "    .nlargest(100, 'dist_sem')\n",
    "    .assign(index_1 = lambda df: df.index + 1)\n",
    "    .assign(dist_sem = lambda df: df['dist_sem'].round(2))\n",
    "    .assign(dist_sem = lambda df: df['dist_sem'].apply('{:.2f}'.format))\n",
    "    .rename({'index_1': '', 'lex': 'Lexeme', 'dist_sem': 'SemDist'}, axis=1)\n",
    ")\n",
    "sem_change_cands_out.to_csv(\n",
    "        f'{OUT_DIR}sem_var_soc_cands.csv',\n",
    "        columns=['', 'Lexeme', 'SemDist'],\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nearest neighbours for target lexemes in both communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEX_NBS = 'plandemic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs_model_1, nbs_model_2 = get_nearest_neighbours_models(\n",
    "    lex=LEX_NBS, \n",
    "    freq_min=10,\n",
    "    model_1=models[0]['model'], \n",
    "    model_2=models[1]['model'],\n",
    "    k=10\n",
    ")\n",
    "\n",
    "display(\n",
    "    nbs_model_1,\n",
    "    nbs_model_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### biggest discrepancies in nearest neighbours for target lexemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs_model_1, nbs_model_2 = get_nearest_neighbours_models(\n",
    "    lex='vaccine', \n",
    "    freq_min=150,\n",
    "    model_1=models[0]['model'], \n",
    "    model_2=models[1]['model'],\n",
    "    k=100_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs_diffs = pd.merge(\n",
    "    nbs_model_1, nbs_model_2, \n",
    "    on='lex',\n",
    "    suffixes = ('_1', '_2')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-audience",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs_diffs = nbs_diffs\\\n",
    "    .assign(sim_diff = abs(nbs_diffs['similarity_1'] - nbs_diffs['similarity_2']))\\\n",
    "    .sort_values('sim_diff', ascending=False)\\\n",
    "    .reset_index(drop=True)\\\n",
    "    .query('lex.str.len() >= 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "topn = 10\n",
    "\n",
    "subr_1_nbs = nbs_diffs\\\n",
    "    .query('similarity_1 > similarity_2')\\\n",
    "    .nlargest(topn, 'sim_diff')\n",
    "\n",
    "subr_2_nbs = nbs_diffs\\\n",
    "    .query('similarity_2 > similarity_1')\\\n",
    "    .nlargest(topn, 'sim_diff')\n",
    "\n",
    "display(subr_1_nbs, subr_2_nbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project embeddings on semantix axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexs = [\n",
    "\t'regulations', 'politics',\n",
    "\t'government', 'mandate', \n",
    "\t'science', 'research',\n",
    "\t'shutdown', 'shutdowns', \n",
    "\t'lockdown', 'lockdowns', \n",
    "\t'vaccine', 'vaccines', \n",
    "\t'mask', 'masks',\n",
    "\t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _good_ vs _bad_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pole_words_pos = ['good', 'bad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_sims_pos = get_axis_sims(lexs, models, pole_words_pos, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_sims_pos_chart = alt.Chart(proj_sims_pos).mark_line(point=True).encode(\n",
    "\tx=alt.X('sim', title='SemSim'),\n",
    "\ty=alt.Y('lex', title='', sort=None),\n",
    "\tcolor=alt.Color('subreddit', title='Community')\n",
    ").properties(title=f'{pole_words_pos[0]} vs {pole_words_pos[1]}')\n",
    "\n",
    "proj_sims_pos_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_sims_pos_chart.save(f'../out/proj-emb_pos_{models[0][\"name\"]}--{models[1][\"name\"]}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _objective_ vs _subjective_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pole_words_subj = ['objective', 'subjective']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_sims_subj = get_axis_sims(lexs, models, pole_words_subj, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_sims_subj_chart = alt.Chart(proj_sims_subj).mark_line(point=True).encode(\n",
    "\tx=alt.X('sim', title='SemSim'),\n",
    "\ty=alt.Y('lex', title='', sort=None),\n",
    "\tcolor=alt.Color('subreddit', title='Community')\n",
    ").properties(title=f'{pole_words_pos[0]} vs {pole_words_pos[1]}')\n",
    "\n",
    "proj_sims_subj_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_sims_subj_chart.save(f'../out/proj-emb_subj_{models[0][\"name\"]}--{models[1][\"name\"]}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = 'vaccine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "nbs_vecs = pd.concat([get_nbs_vecs(lex, model) for model in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quirin/opt/miniconda3/envs/neocov/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/quirin/opt/miniconda3/envs/neocov/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:982: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing pairwise distances...\n",
      "[t-SNE] Computed conditional probabilities for sample 102 / 102\n",
      "[t-SNE] Mean sigma: 11.515156\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 48.863581\n",
      "[t-SNE] KL divergence after 550 iterations: 0.069542\n"
     ]
    }
   ],
   "source": [
    "#data\n",
    "nbs_vecs = dim_red_nbs_vecs(nbs_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gp/dw55jb3d3gl6jn22rscvxjm40000gn/T/ipykernel_23795/1278045993.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnbs_vecs_chart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_nbs_vecs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbs_vecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnbs_vecs_chart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/promo/NeoCov/neocov/neocov/type_emb.py\u001b[0m in \u001b[0;36mplot_nbs_vecs\u001b[0;34m(nbs_vecs, perplexity)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'subreddit'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \t\t)\n\u001b[0;32m--> 278\u001b[0;31m                 \u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Social semantic variation for the word '{lex}'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0madd_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrush\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteraction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \t)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lex' is not defined"
     ]
    }
   ],
   "source": [
    "#data\n",
    "nbs_vecs_chart = plot_nbs_vecs(lex, nbs_vecs)\n",
    "nbs_vecs_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "nbs_vecs_chart.save(f'../out/map-sem-space_{lex}_{models[0][\"name\"]}--{models[1][\"name\"]}.pdf')\n",
    "nbs_vecs_chart.save(f'../out/map-sem-space_{lex}_{models[0][\"name\"]}--{models[1][\"name\"]}.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to interactive chart: https://wuqui.github.io/neocov/#Plot-embedding-space.\n",
    "\n",
    "Press and hold the <kbd>alt</kbd> key to select regions of the semantic space."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
