{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neocov.read_data import *\n",
    "from neocov.preproc import *\n",
    "from neocov.type_emb import *\n",
    "from neocov.communities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/'\n",
    "COMMENTS_DIAC_DIR = f'{DATA_DIR}comments/by_date/'\n",
    "OUT_DIR = '../out/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeoCov\n",
    "\n",
    "> Semantic change and social semantic variation of Covid-related English neologisms on Reddit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = '2020'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_paths_year = get_comments_paths_year(COMMENTS_DIAC_DIR, YEAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "comments = read_comm_csvs(comment_paths_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "comments_clean = clean_comments(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = comments_clean['body'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{OUT_DIR}docs_clean/diac_{YEAR}.pickle', 'wb') as fp:\n",
    "    pickle.dump(docs, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{OUT_DIR}docs_clean/diac_{YEAR}.pickle', 'rb') as fp:\n",
    "    docs = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-driving",
   "metadata": {},
   "source": [
    "#### Create corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = train_model(corpus, EPOCHS=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-flash",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'{OUT_DIR}models/{YEAR}_ep-20.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-necessity",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2019 = Word2Vec.load(f'{OUT_DIR}models/2019_ep-20.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2020 = Word2Vec.load(f'{OUT_DIR}models/2020_ep-20.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-blank",
   "metadata": {},
   "source": [
    "### Align models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2019_vocab = len(model_2019.wv.key_to_index)\n",
    "model_2020_vocab = len(model_2020.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_procrustes_align_gensim(model_2019, model_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(model_2019.wv.key_to_index) == len(model_2020.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_vocab = pd.DataFrame(\n",
    "    columns=['Model', 'Words'],\n",
    "    data=[\n",
    "        ['2019', model_2019_vocab],\n",
    "        ['2020', model_2020_vocab],\n",
    "        ['intersection', len(model_2019.wv.key_to_index)]\n",
    "    ],\n",
    ")\n",
    "\n",
    "models_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_vocab.to_csv(f'{OUT_DIR}models_vocab.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-lighting",
   "metadata": {},
   "source": [
    "### Measure distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = measure_distances(model_2019, model_2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: filter by true type frequency; `Gensim`'s type frequency seems incorrect; it probably reflects frequency ranks instead of total counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist_lex = load_blacklist_lex()\n",
    "\n",
    "k = 500\n",
    "freq_min = 100\n",
    "\n",
    "sem_change_cands = (distances\\\n",
    "    .query('freq_1 > @freq_min and freq_2 > @freq_min')\n",
    "    .query('lex.str.isalpha() == True')\n",
    "    .query('lex.str.len() > 3')\n",
    "    .query('lex not in @blacklist_lex')\n",
    "    .nlargest(k, 'dist_sem')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "sem_change_cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_change_cands_out = (sem_change_cands\n",
    "    .nlargest(100, 'dist_sem')\n",
    "    .assign(index_1 = lambda df: df.index + 1)\n",
    "    .assign(dist_sem = lambda df: df['dist_sem'].round(2))\n",
    "    .assign(dist_sem = lambda df: df['dist_sem'].apply('{:.2f}'.format))\n",
    "    .rename({'index_1': '', 'lex': 'Lexeme', 'dist_sem': 'SemDist'}, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_change_cands_out.to_csv(\n",
    "        f'{OUT_DIR}sem_change_cands.csv',\n",
    "        columns=['', 'Lexeme', 'SemDist'],\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-tomato",
   "metadata": {},
   "source": [
    "### Inspect nearest neighbours of lexemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEX_NBS = 'ahahahah'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs_model_1, nbs_model_2 = get_nearest_neighbours_models(\n",
    "    lex=LEX_NBS, \n",
    "    freq_min=1,\n",
    "    model_1=model_2019, \n",
    "    model_2=model_2020,\n",
    "    k=10\n",
    ")\n",
    "\n",
    "display(\n",
    "    nbs_model_1,\n",
    "    nbs_model_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not related to Covid:\n",
    "\n",
    "- sunsetting: > gaming-related meaning in 2020\n",
    "- childe: > gaming-related proper name in 2020\n",
    "- megalodon: > gaming-related proper name in 2020\n",
    "- newf: (derogatory) slang term for people from Newfoundland (Canada)\n",
    "- chaz: > Capitol Hill Autonomous Zone (CHAZ)\n",
    "- klee: > computer game character, proper name\n",
    "- rittenhouse: whiskey brand > proper name, involved in shooting related to BLM protests\n",
    "\n",
    "Related to Covid:\n",
    "\n",
    "- cerb: > Canada Emergency Response Benefit for Covid\n",
    "- vacuo: > medical term, 'vacuum'\n",
    "- moderna: > vaccine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social semantic variation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-chorus",
   "metadata": {},
   "source": [
    "### Inspect subreddits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-coordinator",
   "metadata": {},
   "source": [
    "#### read comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_dir_path = Path('../data/comments/lexeme/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_paths = list(comments_dir_path.glob(f'Covid*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "comments = read_comm_csvs(comments_paths)\n",
    "comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: filter comments\n",
    "\n",
    "- [ ] remove duplicates\n",
    "- [ ] remove bots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-rocket",
   "metadata": {},
   "source": [
    "#### get subreddit counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "subr_counts = get_subr_counts(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "subr_counts_plt = plot_subr_counts(subr_counts, k=20)\n",
    "subr_counts_plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "subr_counts_plt.save(f'{OUT_DIR}subr_counts.png', scale_factor=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-kentucky",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMENTS_DIR_SUBR = '../data/comments/subr/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBR = 'conspiracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpaths = get_comments_paths_subr(COMMENTS_DIR_SUBR, SUBR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "comments = read_comm_csvs(fpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "comments_clean = clean_comments(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = comments_clean['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = docs.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{OUT_DIR}docs_clean/subr_{SUBR}.pickle', 'wb') as fp:\n",
    "    pickle.dump(docs, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{OUT_DIR}docs_clean/subr_{SUBR}.pickle', 'rb') as fp:\n",
    "    docs = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus information\n",
    "\n",
    "| Subreddit          | Comments  | DateFirst  | DateLast   |\n",
    "|:-------------------|---------: |:-----------|:-----------|\n",
    "| LockdownSkepticism |   520,392 | 2020-03-26 | 2020-12-27 |  \n",
    "| Coronavirus        | 4,121,144 | 2020-01-21 | 2020-12-27 |\n",
    "| conspiracy         | 3,973,514 | 2020-01-01 | 2020-12-27 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = train_model(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'{OUT_DIR}models/{SUBR}.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-necessity",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBRS = ['Coronavirus', 'conspiracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Word2Vec.load(f'{OUT_DIR}models/{SUBRS[0]}.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Word2Vec.load(f'{OUT_DIR}models/{SUBRS[1]}.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-blank",
   "metadata": {},
   "source": [
    "### Align models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_vocab = len(model_1.wv.key_to_index)\n",
    "model_2_vocab = len(model_2.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-clerk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67181 67181\n",
      "67181 67181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x187e17c40>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smart_procrustes_align_gensim(model_1, model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(model_1.wv.key_to_index) == len(model_2.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-cutting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>94816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conspiracy</td>\n",
       "      <td>112599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>intersection</td>\n",
       "      <td>67181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model   Words\n",
       "0   Coronavirus   94816\n",
       "1    conspiracy  112599\n",
       "2  intersection   67181"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_vocab = pd.DataFrame(\n",
    "    columns=['Model', 'Words'],\n",
    "    data=[\n",
    "        [SUBRS[0], model_1_vocab],\n",
    "        [SUBRS[1], model_2_vocab],\n",
    "        ['intersection', len(model_1.wv.key_to_index)]\n",
    "    ],\n",
    ")\n",
    "\n",
    "models_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_vocab.to_csv(f'{OUT_DIR}models_subrs_vocab.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-lighting",
   "metadata": {},
   "source": [
    "### Measure distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = measure_distances(model_1, model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### words that differ the most between both communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-cannon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lex</th>\n",
       "      <th>dist_sem</th>\n",
       "      <th>freq_1</th>\n",
       "      <th>freq_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soliciting</td>\n",
       "      <td>0.989504</td>\n",
       "      <td>2233</td>\n",
       "      <td>2474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resubmit</td>\n",
       "      <td>0.944866</td>\n",
       "      <td>1763</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>waiters</td>\n",
       "      <td>0.929376</td>\n",
       "      <td>149</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>curiously</td>\n",
       "      <td>0.928779</td>\n",
       "      <td>118</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subsequently</td>\n",
       "      <td>0.924492</td>\n",
       "      <td>12174</td>\n",
       "      <td>11956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>anons</td>\n",
       "      <td>0.920569</td>\n",
       "      <td>260</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>blacklivesmatter</td>\n",
       "      <td>0.918460</td>\n",
       "      <td>107</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>redpill</td>\n",
       "      <td>0.914164</td>\n",
       "      <td>119</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>derek</td>\n",
       "      <td>0.913568</td>\n",
       "      <td>211</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>borderline</td>\n",
       "      <td>0.892894</td>\n",
       "      <td>21891</td>\n",
       "      <td>20974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>submissions</td>\n",
       "      <td>0.890047</td>\n",
       "      <td>3777</td>\n",
       "      <td>4093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>promotional</td>\n",
       "      <td>0.887624</td>\n",
       "      <td>344</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mena</td>\n",
       "      <td>0.886735</td>\n",
       "      <td>196</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nicaraguan</td>\n",
       "      <td>0.885770</td>\n",
       "      <td>111</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>acorn</td>\n",
       "      <td>0.885177</td>\n",
       "      <td>105</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>greer</td>\n",
       "      <td>0.883525</td>\n",
       "      <td>105</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>goyim</td>\n",
       "      <td>0.879430</td>\n",
       "      <td>287</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>snowfall</td>\n",
       "      <td>0.873538</td>\n",
       "      <td>208</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>goodyear</td>\n",
       "      <td>0.869714</td>\n",
       "      <td>101</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>submitter</td>\n",
       "      <td>0.869147</td>\n",
       "      <td>260</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 lex  dist_sem  freq_1  freq_2\n",
       "0         soliciting  0.989504    2233    2474\n",
       "1           resubmit  0.944866    1763    1928\n",
       "2            waiters  0.929376     149     206\n",
       "3          curiously  0.928779     118     164\n",
       "4       subsequently  0.924492   12174   11956\n",
       "5              anons  0.920569     260     351\n",
       "6   blacklivesmatter  0.918460     107     150\n",
       "7            redpill  0.914164     119     165\n",
       "8              derek  0.913568     211     287\n",
       "9         borderline  0.892894   21891   20974\n",
       "10       submissions  0.890047    3777    4093\n",
       "11       promotional  0.887624     344     450\n",
       "12              mena  0.886735     196     267\n",
       "13        nicaraguan  0.885770     111     154\n",
       "14             acorn  0.885177     105     147\n",
       "15             greer  0.883525     105     147\n",
       "16             goyim  0.879430     287     386\n",
       "17          snowfall  0.873538     208     283\n",
       "18          goodyear  0.869714     101     141\n",
       "19         submitter  0.869147     260     352"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blacklist_lex = load_blacklist_lex()\n",
    "\n",
    "k = 20\n",
    "freq_min = 100\n",
    "\n",
    "sem_change_cands = (distances\\\n",
    "    .query('freq_1 > @freq_min and freq_2 > @freq_min')\n",
    "    .query('lex.str.isalpha() == True')\n",
    "    .query('lex.str.len() > 3')\n",
    "    .query('lex not in @blacklist_lex')\n",
    "    .nlargest(k, 'dist_sem')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "sem_change_cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_change_cands_out = (sem_change_cands\n",
    "    .nlargest(100, 'dist_sem')\n",
    "    .assign(index_1 = lambda df: df.index + 1)\n",
    "    .assign(dist_sem = lambda df: df['dist_sem'].round(2))\n",
    "    .assign(dist_sem = lambda df: df['dist_sem'].apply('{:.2f}'.format))\n",
    "    .rename({'index_1': '', 'lex': 'Lexeme', 'dist_sem': 'SemDist'}, axis=1)\n",
    ")\n",
    "sem_change_cands_out.to_csv(\n",
    "        f'{OUT_DIR}sem_var_soc_cands.csv',\n",
    "        columns=['', 'Lexeme', 'SemDist'],\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nearest neighbours for target lexemes in both communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEX_NBS = 'lockdown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-majority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>lex</th>\n",
       "      <th>similarity</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>shutdown</td>\n",
       "      <td>0.844873</td>\n",
       "      <td>5413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>lockdowns</td>\n",
       "      <td>0.768522</td>\n",
       "      <td>16637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>shutdowns</td>\n",
       "      <td>0.661069</td>\n",
       "      <td>1632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>curfew</td>\n",
       "      <td>0.613175</td>\n",
       "      <td>1079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>quarantine</td>\n",
       "      <td>0.600933</td>\n",
       "      <td>26502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>restrictions</td>\n",
       "      <td>0.581443</td>\n",
       "      <td>16482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>quarantines</td>\n",
       "      <td>0.568791</td>\n",
       "      <td>1634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>quarentine</td>\n",
       "      <td>0.540457</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>curfews</td>\n",
       "      <td>0.536410</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>containment</td>\n",
       "      <td>0.515410</td>\n",
       "      <td>2526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model           lex  similarity   freq\n",
       "0      1      shutdown    0.844873   5413\n",
       "1      1     lockdowns    0.768522  16637\n",
       "2      1     shutdowns    0.661069   1632\n",
       "3      1        curfew    0.613175   1079\n",
       "4      1    quarantine    0.600933  26502\n",
       "5      1  restrictions    0.581443  16482\n",
       "6      1   quarantines    0.568791   1634\n",
       "7      1    quarentine    0.540457    255\n",
       "8      1       curfews    0.536410    456\n",
       "9      1   containment    0.515410   2526"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>lex</th>\n",
       "      <th>similarity</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29861</th>\n",
       "      <td>2</td>\n",
       "      <td>lockdowns</td>\n",
       "      <td>0.794638</td>\n",
       "      <td>15881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29862</th>\n",
       "      <td>2</td>\n",
       "      <td>shutdown</td>\n",
       "      <td>0.726183</td>\n",
       "      <td>5529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29863</th>\n",
       "      <td>2</td>\n",
       "      <td>quarantine</td>\n",
       "      <td>0.723483</td>\n",
       "      <td>24948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29864</th>\n",
       "      <td>2</td>\n",
       "      <td>shutdowns</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>1805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29865</th>\n",
       "      <td>2</td>\n",
       "      <td>quarantines</td>\n",
       "      <td>0.622162</td>\n",
       "      <td>1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29866</th>\n",
       "      <td>2</td>\n",
       "      <td>curfew</td>\n",
       "      <td>0.595864</td>\n",
       "      <td>1236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29867</th>\n",
       "      <td>2</td>\n",
       "      <td>restrictions</td>\n",
       "      <td>0.583930</td>\n",
       "      <td>15817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29868</th>\n",
       "      <td>2</td>\n",
       "      <td>curfews</td>\n",
       "      <td>0.581970</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29869</th>\n",
       "      <td>2</td>\n",
       "      <td>pandemic</td>\n",
       "      <td>0.580793</td>\n",
       "      <td>67364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29870</th>\n",
       "      <td>2</td>\n",
       "      <td>quarentine</td>\n",
       "      <td>0.528733</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model           lex  similarity   freq\n",
       "29861      2     lockdowns    0.794638  15881\n",
       "29862      2      shutdown    0.726183   5529\n",
       "29863      2    quarantine    0.723483  24948\n",
       "29864      2     shutdowns    0.702284   1805\n",
       "29865      2   quarantines    0.622162   1806\n",
       "29866      2        curfew    0.595864   1236\n",
       "29867      2  restrictions    0.583930  15817\n",
       "29868      2       curfews    0.581970    577\n",
       "29869      2      pandemic    0.580793  67364\n",
       "29870      2    quarentine    0.528733    346"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nbs_model_1, nbs_model_2 = get_nearest_neighbours_models(\n",
    "    lex=LEX_NBS, \n",
    "    freq_min=50,\n",
    "    model_1=model_1, \n",
    "    model_2=model_2,\n",
    "    k=10\n",
    ")\n",
    "\n",
    "display(\n",
    "    nbs_model_1,\n",
    "    nbs_model_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### embeddings projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "import altair as alt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append({'subreddit': SUBRS[0], 'model': model_1})\n",
    "models.append({'subreddit': SUBRS[1], 'model': model_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pole_avg(model, lex, k):\n",
    "\tvecs = []\n",
    "\tvecs.append(model.wv[lex])\n",
    "\tfor closest_word, similarity in model.wv.most_similar(positive=lex, topn=k):\n",
    "\t\tvecs.append(model.wv[closest_word])\n",
    "\tpole_avg = np.mean(vecs, axis=0)\n",
    "\treturn pole_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sem_axis(model, pole_word_1: str, pole_word_2: str):\n",
    "\tpole_1_vec = model_1.wv.get_vector(pole_1)\n",
    "\tpole_2_vec = model_1.wv.get_vector(pole_2)\n",
    "\tsem_axis = pole_1_vec - pole_2_vec\n",
    "\treturn sem_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sem_axis_avg(model, pole_word_1: str, pole_word_2: str):\n",
    "\tpole_1_vec = model_1.wv.get_vector(pole_1)\n",
    "\tpole_2_vec = model_1.wv.get_vector(pole_2)\n",
    "\tpole_1_avg = get_pole_avg(model_1, pole_word_1, k=10)\n",
    "\tpole_2_avg = get_pole_avg(model_1, pole_word_2, k=10)\n",
    "\tsem_axis = pole_1_avg - pole_2_avg\n",
    "\treturn sem_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_axis_sim(lex: str, pole_word_1: str, pole_word_2: str, model):\n",
    "\tsem_axis = make_sem_axis_avg(model, pole_word_1, pole_word_2)\n",
    "\tlex_vec = model.wv.get_vector(lex)\n",
    "\tsim_cos = 1 - spatial.distance.cosine(lex_vec, sem_axis)\n",
    "\treturn sim_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = 'lockdown'\n",
    "pole_1 = 'good'\n",
    "pole_2 = 'bad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexs = [\n",
    "\t'lockdown', 'lockdowns', \n",
    "\t'shutdown', 'shutdowns', \n",
    "\t'vaccine', 'vaccines', \n",
    "\t'mask', 'masks',\n",
    "\t'order', 'police', 'science', 'mandate',\n",
    "\t'thing', 'tree', \n",
    "\t'give', 'take'\n",
    "\t# 'happy', 'sad',\n",
    "\t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = []\n",
    "for lex in lexs:\n",
    "\tfor model in models:\n",
    "\t\tsim = {}\n",
    "\t\tsim['subreddit'] = model['subreddit']\n",
    "\t\tsim['lex'] = lex\n",
    "\t\tsim['sim'] = get_axis_sim(lex, pole_1, pole_2, model['model'])\n",
    "\t\tsims.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-b3abe0aaafb14650ac220c6fa898517c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-b3abe0aaafb14650ac220c6fa898517c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-b3abe0aaafb14650ac220c6fa898517c\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-aab3a02273668f9c5dc01b4c2a123765\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"subreddit\", \"type\": \"nominal\"}, \"x\": {\"field\": \"sim\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"lex\", \"sort\": null, \"type\": \"nominal\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-aab3a02273668f9c5dc01b4c2a123765\": [{\"subreddit\": \"Coronavirus\", \"lex\": \"lockdown\", \"sim\": -0.020428422838449478}, {\"subreddit\": \"conspiracy\", \"lex\": \"lockdown\", \"sim\": -0.11954280734062195}, {\"subreddit\": \"Coronavirus\", \"lex\": \"lockdowns\", \"sim\": -0.03195760399103165}, {\"subreddit\": \"conspiracy\", \"lex\": \"lockdowns\", \"sim\": -0.09696231037378311}, {\"subreddit\": \"Coronavirus\", \"lex\": \"shutdown\", \"sim\": -0.0030814199708402157}, {\"subreddit\": \"conspiracy\", \"lex\": \"shutdown\", \"sim\": -0.07952913641929626}, {\"subreddit\": \"Coronavirus\", \"lex\": \"shutdowns\", \"sim\": -0.061103351414203644}, {\"subreddit\": \"conspiracy\", \"lex\": \"shutdowns\", \"sim\": -0.09631608426570892}, {\"subreddit\": \"Coronavirus\", \"lex\": \"vaccine\", \"sim\": 0.027036398649215698}, {\"subreddit\": \"conspiracy\", \"lex\": \"vaccine\", \"sim\": -0.057832762598991394}, {\"subreddit\": \"Coronavirus\", \"lex\": \"vaccines\", \"sim\": 0.02113475278019905}, {\"subreddit\": \"conspiracy\", \"lex\": \"vaccines\", \"sim\": -0.025540443137288094}, {\"subreddit\": \"Coronavirus\", \"lex\": \"mask\", \"sim\": 0.02409209869801998}, {\"subreddit\": \"conspiracy\", \"lex\": \"mask\", \"sim\": -0.06673668324947357}, {\"subreddit\": \"Coronavirus\", \"lex\": \"masks\", \"sim\": 0.042272794991731644}, {\"subreddit\": \"conspiracy\", \"lex\": \"masks\", \"sim\": -0.022345764562487602}, {\"subreddit\": \"Coronavirus\", \"lex\": \"order\", \"sim\": 0.03343459591269493}, {\"subreddit\": \"conspiracy\", \"lex\": \"order\", \"sim\": -0.013651296496391296}, {\"subreddit\": \"Coronavirus\", \"lex\": \"police\", \"sim\": 0.05815239995718002}, {\"subreddit\": \"conspiracy\", \"lex\": \"police\", \"sim\": 0.009731519035995007}, {\"subreddit\": \"Coronavirus\", \"lex\": \"science\", \"sim\": -0.04062918573617935}, {\"subreddit\": \"conspiracy\", \"lex\": \"science\", \"sim\": -0.01712346449494362}, {\"subreddit\": \"Coronavirus\", \"lex\": \"mandate\", \"sim\": 0.050309017300605774}, {\"subreddit\": \"conspiracy\", \"lex\": \"mandate\", \"sim\": 0.023100711405277252}, {\"subreddit\": \"Coronavirus\", \"lex\": \"thing\", \"sim\": -0.09180065989494324}, {\"subreddit\": \"conspiracy\", \"lex\": \"thing\", \"sim\": -0.06663163006305695}, {\"subreddit\": \"Coronavirus\", \"lex\": \"tree\", \"sim\": -0.00044312604586593807}, {\"subreddit\": \"conspiracy\", \"lex\": \"tree\", \"sim\": 0.0230832789093256}, {\"subreddit\": \"Coronavirus\", \"lex\": \"give\", \"sim\": 0.04639571160078049}, {\"subreddit\": \"conspiracy\", \"lex\": \"give\", \"sim\": 0.029668521136045456}, {\"subreddit\": \"Coronavirus\", \"lex\": \"take\", \"sim\": -0.0009267961140722036}, {\"subreddit\": \"conspiracy\", \"lex\": \"take\", \"sim\": -0.025768481194972992}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims_df = pd.DataFrame(sims)\n",
    "\n",
    "alt.Chart(sims_df).mark_line(point=True).encode(\n",
    "\tx='sim',\n",
    "\ty=alt.Y('lex', sort=None),\n",
    "\tcolor='subreddit'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### biggest discrepancies in nearest neighbours for target lexemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs_model_1, nbs_model_2 = get_nearest_neighbours_models(\n",
    "    lex=LEX, \n",
    "    freq_min=150,\n",
    "    model_1=model_1, \n",
    "    model_2=model_2,\n",
    "    k=100_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs_diffs = pd.merge(\n",
    "    nbs_model_1, nbs_model_2, \n",
    "    on='lex',\n",
    "    suffixes = ('_1', '_2')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-audience",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs_diffs = nbs_diffs\\\n",
    "    .assign(sim_diff = abs(nbs_diffs['similarity_1'] - nbs_diffs['similarity_2']))\\\n",
    "    .sort_values('sim_diff', ascending=False)\\\n",
    "    .reset_index(drop=True)\\\n",
    "    .query('lex.str.len() >= 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "topn = 10\n",
    "\n",
    "subr_1_nbs = nbs_diffs\\\n",
    "    .query('similarity_1 > similarity_2')\\\n",
    "    .nlargest(topn, 'sim_diff')\n",
    "\n",
    "subr_2_nbs = nbs_diffs\\\n",
    "    .query('similarity_2 > similarity_1')\\\n",
    "    .nlargest(topn, 'sim_diff')\n",
    "\n",
    "display(subr_1_nbs, subr_2_nbs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
